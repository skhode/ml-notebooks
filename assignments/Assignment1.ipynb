{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDS 575: Assignment 1\n",
    "\n",
    "- Turn in solutions as a single notebook (ipynb) _and_ as a pdf on Blackboard. No need to turn in datasets/word-docs.\n",
    "- Answer the following questions concisely, in complete sentences and with full clarity. Across group collaboration is _strictly_ not allowed. Always cite all your sources.\n",
    "- Make appropriate assumptions necessary in order to answer the questions, and mention them explicitly at the beginning of each answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Python Basics (3pt)\n",
    "\n",
    "1. Numpy\n",
    "  1. Create a $2\\times 2$ numpy array of all ones.\n",
    "  2. Create a $3\\times 3$ numpy identity matrix.\n",
    "  3. Let `a = np.array([[1,3,5,9], [6,6,8,8], [12,11,11,12]])`. Use slicing to obtain the first row thrid and fourth cells. Display the shape of the array using [array attributes](https://numpy.org/doc/stable/reference/arrays.ndarray.html#array-attributes).\n",
    "  4. Find all elements in `a` that are greater than 10 using boolean indexing.\n",
    "  5. Change the data type of the elements in `a` to `numpy.int64`. Can you find the memory footprint of `a` before and after this change?\n",
    "\n",
    "2. Pandas\n",
    "  1. Create a pandas series object with entries `[10,20,30,30,30,10,20,100,100, numpy.nan]`.\n",
    "  2. Create a pandas dataframe from a dictionary (create an example dictionary with different types of values such as strings, integers, pandas series objects etc).\n",
    "  3. Display the data types of the above dataframe. Also show the head and tail samples.\n",
    "  4. What does the describe method do? Show its operation on the dataframe created above.\n",
    "  5. Download the [iris dataset](https://www.kaggle.com/uciml/iris?select=Iris.csv) and use the `read_csv` method to read the data into a data frame. Display the data types, show a sample and describe the dataframe.\n",
    " \n",
    "3. Matplotlib\n",
    "  1. Create a x-y plot of the series object create above after dropping the last element. Change the y-label and x-label to 'prices' and 'years' respectively.\n",
    "  2. Change the tick labels to reflect years starting from 2001.\n",
    "  3. Add a legend and a plot title.\n",
    "  4. In a new figure, make two identical sub-plots with the data `numpy.linspace(0, 2, 100)`.\n",
    "  5. Create categories `['Chicago','NYC','Austin','Seattle']`. Generate a random number corresponding to each category using numpy. Make a bar plot with the appropriate category labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Datasets (2pt)\n",
    "1. Use the [make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) and [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) functions in scikit-learn to create two datasets.\n",
    "\n",
    "2. Perform a exploratory analysis of these two datasets.\n",
    "  1. Describe the feature wise statistics if any. \n",
    "  2. Plot the marginal distributions.\n",
    "  3. What is the size of the input space?\n",
    "  4. What is the size of the output space?\n",
    "  5. How can the same datasets be obtained if the functions are rerun? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement K Nearest Neighbor (4pt)\n",
    "\n",
    "1. Create a random two dimensional classification dataset (N=100) based on Q2. Assign a different color to each class uniformly at random and plot using matplotib.\n",
    "2. Generate 10 new points that belong to the same input space. Plot them using a different color in the above plot.\n",
    "3. Write the unweighted K Nearest Neighbor API from scratch. Define the class appropraitely such that knn object instances with different values of `k` can be created. Define similarity using Euclidean distance.\n",
    "4. Draw the decision boundaries when `k` equals 1, 10 and 100.\n",
    "5. provide the labels for the 10 unlabeled points for each of these settings in a pandas dataframe with 10 rows and three columns (corresponding to each value of `k`) and display it.\n",
    "6. Instantiate the k nearest neighbor from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) and compare the decision boundaries and labels obtained from your method.\n",
    "7. Repeat steps 1-6 for a random two dimensional regression dataset based on Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement Decision Trees (3pt)\n",
    "\n",
    "1. Create three two dimensional datasets (with two classes and 100 rows) using [1](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html#sklearn.datasets.make_moons), [2](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles) and [3](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs). Plot them using matplotlib.\n",
    "2. Write the decision tree model class that uses training accuracy to make splits from scratch. The class should be able to handle other splitting criteria, namely entropy and Gini index as well.\n",
    "3. Draw the decision boundary obtained from instantiating a tree obtain based on the above class and applying it to the three datasets above. \n",
    "4. How does the splitting criteria influence the decision boundaries?\n",
    "5. Comment on whether zero training error is achieved for each of the three datasets.\n",
    "6. Compare and contrast the performance of your tree model with that of [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier).\n",
    "7. Repeat steps 1-6 for a random two dimensional regression dataset based on Q2. You will have to use a different [reference](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor) model in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
