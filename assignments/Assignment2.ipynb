{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDS 575: Assignment 2\n",
    "\n",
    "- Turn in solutions as a single notebook (ipynb) _and_ as a pdf on Blackboard. No need to turn in datasets/word-docs.\n",
    "- Answer the following questions concisely, in complete sentences and with full clarity. Across group collaboration is _strictly_ not allowed. Always cite all your sources.\n",
    "- Make appropriate assumptions necessary in order to answer the questions, and mention them explicitly at the beginning of each answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gradient Descent (6pt)\n",
    "1. Implement the Batch Gradient Descent (BGD) procedure. \n",
    "  - It should take as inputs:\n",
    "    - the number of epochs (an integer)\n",
    "    - the starting/initial point (a numpy array)\n",
    "    - the learning rate (a real value), and\n",
    "    - the gradient function (a function that take a point as input and produces the gradient of the loss with respect to the point as output), and its necessary inputs.\n",
    "  - It should return:\n",
    "    - all iterates (as a list/numpy array),\n",
    "    - the final iterate (as a numpy array), and\n",
    "    - the absolute and relative changes corresponding to the final iterate (make suitable assumptions if needed).\n",
    "2. Write the gradient function (G) corresponding to linear model and the squared loss.\n",
    "  - It should take as inputs:\n",
    "    - a regression dataset (a pandas dataframe), and\n",
    "    - the point (a numpy array) at which the gradient needs to be evaluated\n",
    "  - It should return:\n",
    "    - the gradient of the squared loss with respect to the input point.\n",
    "3. Consider a simple regression setting. \n",
    "  1. Generate a regression dataset of appropriate size using make_regression function from scikit-learn. It should have one feature and one target variable.\n",
    "  2. Evaluate BGD when \n",
    "    - the number of epochs is 1000,\n",
    "    - the starting point is numpy.random.randn(2),\n",
    "    - the learning rate is 0.01, and\n",
    "    - the gradient function is G (which uses the dataset generated in the previous step)\n",
    "  3. Plot the magnitude of the gradients as a function of epoch (e.g., using matplotlib). Is there a pattern to the magnitudes?\n",
    "  4. Plot the iterates on the 2D plane. Do they visually indicate convergence?\n",
    "  5. Plot the loss function with respect to the slope and intercept parameters. Is the function convex?\n",
    "  6. Vary the epochs and learning rates and redo steps C-E above. Compare and contrast your results to the settings specified in step B.\n",
    "4. Implement the Stochastic Gradient Descent (SGD) procedure. Redo steps B-F in part 3 and comment on how this procedure may yield different results compared to BGD.\n",
    "5. Implement the Mini-batch Gradient Descent (MBGD) procedure where the batch size is an input. Redo steps B-F in part 3 for two different batch sizes, and comment on how this procedure may yield different results compared to SGD and BGD.\n",
    "6. Modify the loss function to be $$(h_{\\theta}(x)-y)^4$$ and repeat steps B-F in part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classification using Regression (5pt)\n",
    "\n",
    "1. Download the [Adult dataset](https://drive.google.com/file/d/1UJ45CQBg0wJh0KbxBzqTh9s798KtfxLO/view?usp=sharing) and read it into a dataframe using pandas.\n",
    "  - Display the top few rows of the dataframe using `head()`.\n",
    "  - Separate the variables into those that are categorical and those that are numeric and display them. \n",
    "  - For the variables that are categorical, report the unique values and their counts. \n",
    "  - For each feature, also plot the normalized distribution of occurance of the values using a bar plot, after sorting them according to their occurance.\n",
    "6. Our primary aim is to predict the `class` column using the other attributes. That is, we want to predict whether a person earns over 50K a year from heterogeneous data such as age, employment, education, family information, etc. This is a classification problem, and our objective in this question is to solve for it using linear regression.\n",
    "  - Describe how we can build a classifier using a linear model.\n",
    "  - Is the dataset balanced? Why or why not?\n",
    "  - Write a function from scratch to split the dataset 80:20 into training and validation sets. Report the number of observations obtained in each set.\n",
    "8. Perform basic exploratory analysis by computing and visualizing correlations between features. \n",
    "    - Draw the plot of correlations between every pair of features. \n",
    "    - Which features are highly correlated one another?\n",
    "    - Is the data matrix tall or wide?\n",
    "9. Perform linear regression using the above BGD (or SGD or MBGD, your choice) procedure. \n",
    "    - What is the the output variable for regression? Is it the same as the `class` column? If not, how is it related to it?\n",
    "    - Is there any predictability in predicting the output variable in our dataset?\n",
    "    - Plot the histogram of residuals using pandas directly (e.g., `df.hist(bins=...)`). What number of bins was useful for your visualization? \n",
    "    - Are the residuals normally distributed? What is their mean and variance?\n",
    "    - Compare the solution obtained with the one that can be derived using normal equations (compute this using numpy). That is, \n",
    "    $$\\theta_{analytical} = (X^{T}X)^{-1}X^{T}y.$$\n",
    "    - Computationally show that $ X^{T}X $ is positive definite by computing all its eigenvalues and showing that they are positive and real.\n",
    "10. Given the solution of linear regression, predict the `class` column and report mis-classification error on validation data. Compare the performance of this classifier against decision tree classifier that you have implemented in Assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Likelihood Maximization (1pt)\n",
    "\n",
    "Consider the function $\\theta^3(1-\\theta)^7$.  Let $\\alpha$ be such that $\\theta = 1/(1+e^{-\\alpha})$. \n",
    " - Plot the function when $\\alpha$ is between -6 and 6. \n",
    " - Maximize the function over $\\alpha$ using SGD that was implemented in Q1.\n",
    " - Maximize the log of the function over $\\alpha$ using SGD. Are the solutions obtained the same? Why/Why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
